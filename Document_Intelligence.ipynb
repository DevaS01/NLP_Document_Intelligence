{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb177462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./opt/anaconda3/lib/python3.9/site-packages(0.0.309)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./opt/anaconda3/lib/python3.9/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./opt/anaconda3/lib/python3.9/site-packages (from langchain) (1.4.22)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./opt/anaconda3/lib/python3.9/site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: anyio<4.0 in ./opt/anaconda3/lib/python3.9/site-packages (from langchain) (2.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in ./opt/anaconda3/lib/python3.9/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./opt/anaconda3/lib/python3.9/site-packages (from langchain) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./opt/anaconda3/lib/python3.9/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.40 in ./opt/anaconda3/lib/python3.9/site-packages (from langchain) (0.0.43)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./opt/anaconda3/lib/python3.9/site-packages (from langchain) (1.20.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./opt/anaconda3/lib/python3.9/site-packages (from langchain) (2.4.2)\n",
      "Requirement already satisfied: requests<3,>=2 in ./opt/anaconda3/lib/python3.9/site-packages (from langchain) (2.26.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in ./opt/anaconda3/lib/python3.9/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (21.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in ./opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in ./opt/anaconda3/lib/python3.9/site-packages (from anyio<4.0->langchain) (3.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./opt/anaconda3/lib/python3.9/site-packages (from anyio<4.0->langchain) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./opt/anaconda3/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./opt/anaconda3/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in ./opt/anaconda3/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./opt/anaconda3/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2->langchain) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2021.10.8)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./opt/anaconda3/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain) (1.1.1)\n",
      "Requirement already satisfied: packaging>=17.0 in ./opt/anaconda3/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (21.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./opt/anaconda3/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (0.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./opt/anaconda3/lib/python3.9/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (3.0.4)\n",
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ab6bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"openai.api_key\"]=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "791b8355",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4m/86yjzx61095f32qjrs3nfd040000gp/T/ipykernel_16455/3028061378.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo-16k\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"what is the best hill station in India?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "from langchain.llms import openai\n",
    "\n",
    "llm = openai(temperature=0.9,model_name=\"gpt-3.5-turbo-16k\")\n",
    "text = \"what is the best hill station in India?\"\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d48f847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Obtaining dependency information for transformers from https://files.pythonhosted.org/packages/1a/d1/3bba59606141ae808017f6fde91453882f931957f125009417b87a281067/transformers-4.34.0-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.34.0-py3-none-any.whl.metadata (121 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.5/121.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in ./opt/anaconda3/lib/python3.9/site-packages (from transformers) (3.3.1)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/aa/f3/3fc97336a0e90516901befd4f500f08d691034d387406fdbde85bea827cc/huggingface_hub-0.17.3-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in ./opt/anaconda3/lib/python3.9/site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./opt/anaconda3/lib/python3.9/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./opt/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./opt/anaconda3/lib/python3.9/site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: requests in ./opt/anaconda3/lib/python3.9/site-packages (from transformers) (2.26.0)\n",
      "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
      "  Obtaining dependency information for tokenizers<0.15,>=0.14 from https://files.pythonhosted.org/packages/47/51/a921331f1a45a2dd689286720596d47a3a275c919e1de2c6f31985a7d11d/tokenizers-0.14.1-cp39-cp39-macosx_10_7_x86_64.whl.metadata\n",
      "  Downloading tokenizers-0.14.1-cp39-cp39-macosx_10_7_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers)\n",
      "  Obtaining dependency information for safetensors>=0.3.1 from https://files.pythonhosted.org/packages/e3/d2/3279544d8f089a32570cf86a14364c2d9e16cda441795a7cae9031ade746/safetensors-0.4.0-cp39-cp39-macosx_10_7_x86_64.whl.metadata\n",
      "  Downloading safetensors-0.4.0-cp39-cp39-macosx_10_7_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./opt/anaconda3/lib/python3.9/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: fsspec in ./opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2021.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in ./opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.2)\n",
      "Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.0-cp39-cp39-macosx_10_7_x86_64.whl (439 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.7/439.7 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.14.1-cp39-cp39-macosx_10_7_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fb0ee30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\n",
      "  Obtaining dependency information for pdfplumber from https://files.pythonhosted.org/packages/c1/f9/1a41afffe5e7a98ab9b6a6dd3dab9d99b677fae2536f676397c4506f6554/pdfplumber-0.10.2-py3-none-any.whl.metadata\n",
      "  Downloading pdfplumber-0.10.2-py3-none-any.whl.metadata (35 kB)\n",
      "Collecting pdfminer.six==20221105 (from pdfplumber)\n",
      "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting Pillow>=9.1 (from pdfplumber)\n",
      "  Obtaining dependency information for Pillow>=9.1 from https://files.pythonhosted.org/packages/32/e4/c955de57d75aa73ebd65dd4cfe56bb3b806de85c1c791ae447af1ac7efc0/Pillow-10.0.1-cp39-cp39-macosx_10_10_x86_64.whl.metadata\n",
      "  Downloading Pillow-10.0.1-cp39-cp39-macosx_10_10_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Obtaining dependency information for pypdfium2>=4.18.0 from https://files.pythonhosted.org/packages/b2/f1/d413cdc7e33b388604dd9f8db97eb2a50dc0849c627cc3ff582a659e273d/pypdfium2-4.20.0-py3-none-macosx_10_13_x86_64.whl.metadata\n",
      "  Downloading pypdfium2-4.20.0-py3-none-macosx_10_13_x86_64.whl.metadata (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in ./opt/anaconda3/lib/python3.9/site-packages (from pdfminer.six==20221105->pdfplumber) (2.0.4)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six==20221105->pdfplumber)\n",
      "  Obtaining dependency information for cryptography>=36.0.0 from https://files.pythonhosted.org/packages/bb/c1/e8ca19a3e9ac5c867efa6f23ce0b119ad00a16b6019e49a298b8c1fe6866/cryptography-41.0.4-cp37-abi3-macosx_10_12_x86_64.whl.metadata\n",
      "  Downloading cryptography-41.0.4-cp37-abi3-macosx_10_12_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in ./opt/anaconda3/lib/python3.9/site-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (1.14.6)\n",
      "Requirement already satisfied: pycparser in ./opt/anaconda3/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (2.20)\n",
      "Downloading pdfplumber-0.10.2-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.5/47.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Pillow-10.0.1-cp39-cp39-macosx_10_10_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pypdfium2-4.20.0-py3-none-macosx_10_13_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading cryptography-41.0.4-cp37-abi3-macosx_10_12_x86_64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: pypdfium2, Pillow, cryptography, pdfminer.six, pdfplumber\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 8.4.0\n",
      "    Uninstalling Pillow-8.4.0:\n",
      "      Successfully uninstalled Pillow-8.4.0\n",
      "  Attempting uninstall: cryptography\n",
      "    Found existing installation: cryptography 3.4.8\n",
      "    Uninstalling cryptography-3.4.8:\n",
      "      Successfully uninstalled cryptography-3.4.8\n",
      "Successfully installed Pillow-10.0.1 cryptography-41.0.4 pdfminer.six-20221105 pdfplumber-0.10.2 pypdfium2-4.20.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b0e8cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in ./opt/anaconda3/lib/python3.9/site-packages (from sentence_transformers) (4.34.0)\n",
      "Requirement already satisfied: tqdm in ./opt/anaconda3/lib/python3.9/site-packages (from sentence_transformers) (4.62.3)\n",
      "Requirement already satisfied: torch>=1.6.0 in ./opt/anaconda3/lib/python3.9/site-packages (from sentence_transformers) (2.1.0)\n",
      "Collecting torchvision (from sentence_transformers)\n",
      "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/12/46/2a12963c071ac4b85eea63b5b414d7fc62c971dde497279247f852fcc113/torchvision-0.16.0-cp39-cp39-macosx_10_13_x86_64.whl.metadata\n",
      "  Using cached torchvision-0.16.0-cp39-cp39-macosx_10_13_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in ./opt/anaconda3/lib/python3.9/site-packages (from sentence_transformers) (1.20.3)\n",
      "Requirement already satisfied: scikit-learn in ./opt/anaconda3/lib/python3.9/site-packages (from sentence_transformers) (0.24.2)\n",
      "Requirement already satisfied: scipy in ./opt/anaconda3/lib/python3.9/site-packages (from sentence_transformers) (1.7.1)\n",
      "Requirement already satisfied: nltk in ./opt/anaconda3/lib/python3.9/site-packages (from sentence_transformers) (3.6.5)\n",
      "Requirement already satisfied: sentencepiece in ./opt/anaconda3/lib/python3.9/site-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in ./opt/anaconda3/lib/python3.9/site-packages (from sentence_transformers) (0.17.3)\n",
      "Requirement already satisfied: filelock in ./opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.3.1)\n",
      "Requirement already satisfied: fsspec in ./opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2021.8.1)\n",
      "Requirement already satisfied: requests in ./opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (21.0)\n",
      "Requirement already satisfied: sympy in ./opt/anaconda3/lib/python3.9/site-packages (from torch>=1.6.0->sentence_transformers) (1.9)\n",
      "Requirement already satisfied: networkx in ./opt/anaconda3/lib/python3.9/site-packages (from torch>=1.6.0->sentence_transformers) (2.6.3)\n",
      "Requirement already satisfied: jinja2 in ./opt/anaconda3/lib/python3.9/site-packages (from torch>=1.6.0->sentence_transformers) (2.11.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2021.8.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in ./opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.4.0)\n",
      "Requirement already satisfied: click in ./opt/anaconda3/lib/python3.9/site-packages (from nltk->sentence_transformers) (8.0.3)\n",
      "Requirement already satisfied: joblib in ./opt/anaconda3/lib/python3.9/site-packages (from nltk->sentence_transformers) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->sentence_transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./opt/anaconda3/lib/python3.9/site-packages (from torchvision->sentence_transformers) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in ./opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (1.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in ./opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./opt/anaconda3/lib/python3.9/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.2.1)\n",
      "Using cached torchvision-0.16.0-cp39-cp39-macosx_10_13_x86_64.whl (1.7 MB)\n",
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: torchvision, sentence_transformers\n",
      "Successfully installed sentence_transformers-2.2.2 torchvision-0.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08416139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tika import parser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "#try:\n",
    "document = parser.from_file('Test_document_usecase-1.pdf')\n",
    "data = document['content']\n",
    "\n",
    "'''except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n",
    "document = parser.from_file('/Users/dsubramanian/NLP/Test_document_usecase-1.pdf')\n",
    "\n",
    "data = document['content']'''\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter()\n",
    "paragraphs = splitter.split_text(text=data)\n",
    "\n",
    "def clean_text(text):\n",
    "    cleaned_string = text.replace(\"\\n\",\"\").replace('..',\"\")\n",
    "    return cleaned_string\n",
    "\n",
    "cleaned_paragraph = [clean_text(para) for para in paragraphs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17201444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Bitcoin: A Peer-to-Peer Electronic Cash SystemSatoshi Nakamotosatoshin@gmx.comwww.bitcoin.orgAbstract.  A purely  peer-to-peer  version  of  electronic  cash  would  allow online payments to be sent directly from one party to another without going through a financial institution.  Digital signatures provide part of the solution, but the main benefits are lost if a trusted third party is still required to prevent double-spending. We propose a solution to the double-spending problem using a peer-to-peer network. The network timestamps transactions by hashing them into an ongoing chain of hash-based proof-of-work, forming a record that cannot be changed without redoing the proof-of-work.  The longest chain not only serves as proof of the sequence of events witnessed, but proof that it came from the largest pool of CPU power.  As long as a majority of CPU power is controlled by nodes that are not cooperating to attack the network, they'll generate the longest chain and outpace attackers.  The network itself requires minimal structure.  Messages are broadcast on a best effort basis,  and nodes can leave and rejoin the network at  will,  accepting the longest proof-of-work chain as proof of what happened while they were gone.1. IntroductionCommerce on the Internet has come to rely almost exclusively on financial institutions serving as trusted third parties to process electronic payments.  While the system works well enough for most  transactions,  it  still  suffers  from  the  inherent  weaknesses  of  the  trust  based  model. Completely non-reversible transactions are not really possible, since financial institutions cannot avoid  mediating  disputes.   The  cost  of  mediation  increases  transaction  costs,  limiting  the minimum practical transaction size and cutting off the possibility for small casual transactions, and  there  is  a  broader  cost  in  the  loss  of  ability  to  make  non-reversible  payments  for  non-reversible services.  With the possibility of reversal, the need for trust spreads.  Merchants must be wary of their customers, hassling them for more information than they would otherwise need. A certain percentage of fraud is accepted as unavoidable.  These costs and payment uncertainties can be avoided in person by using physical currency, but no mechanism exists to make payments over a communications channel without a trusted party.What is needed is an electronic payment system based on cryptographic proof instead of trust, allowing any two willing parties to transact directly with each other without the need for a trusted third party.  Transactions that are computationally impractical to reverse would protect sellers from fraud, and routine escrow mechanisms could easily be implemented to protect buyers.  In this paper, we propose a solution to the double-spending problem using a peer-to-peer distributed timestamp server to generate computational proof of the chronological order of transactions.  The system  is  secure  as  long  as  honest  nodes  collectively  control  more  CPU  power  than  any cooperating group of attacker nodes.12. TransactionsWe define an electronic coin as a chain of digital signatures.  Each owner transfers the coin to the next by digitally signing a hash of the previous transaction and the public key of the next owner and adding these to the end of the coin.  A payee can verify the signatures to verify the chain of ownership.\", \"The problem of course is the payee can't verify that one of the owners did not double-spend the coin.  A common solution is to introduce a trusted central authority, or mint, that checks every transaction for double spending.  After each transaction, the coin must be returned to the mint to issue a new coin, and only coins issued directly from the mint are trusted not to be double-spent. The  problem with  this  solution  is  that  the  fate  of  the  entire  money  system depends  on  the company running the mint, with every transaction having to go through them, just like a bank.We need a way for the payee to  know that the  previous owners did not  sign any earlier transactions.  For our purposes, the earliest transaction is the one that counts, so we don't care about later attempts to double-spend.  The only way to confirm the absence of a transaction is to be aware of all transactions.  In the mint based model, the mint was aware of all transactions and decided which arrived first.   To accomplish this without a trusted party, transactions must be publicly announced [1], and we need a system for participants to agree on a single history of the order in which they were received.  The payee needs proof that at the time of each transaction, the majority of nodes agreed it was the first received. 3. Timestamp ServerThe solution we propose begins with a timestamp server.  A timestamp server works by taking a hash  of  a  block  of  items  to  be  timestamped  and  widely  publishing  the  hash,  such  as  in  a newspaper or Usenet post [2-5].  The timestamp proves that the data must have existed at the time, obviously, in order to get into the hash.  Each timestamp includes the previous timestamp in its hash, forming a chain, with each additional timestamp reinforcing the ones before it.2BlockItem Item .HashBlockItem Item .HashTransactionOwner 1'sPublic KeyOwner 0'sSignatureHashTransactionOwner 2'sPublic KeyOwner 1'sSignatureHash VerifyTransactionOwner 3'sPublic KeyOwner 2'sSignatureHash VerifyOwner 2'sPrivate KeyOwner 1'sPrivate KeySign  Sign  Owner 3'sPrivate Key4. Proof-of-WorkTo implement a distributed timestamp server on a peer-to-peer basis, we will need to use a proof-of-work system similar to Adam Back's Hashcash [6], rather than newspaper or Usenet posts. The proof-of-work involves scanning for a value that when hashed, such as with SHA-256, the hash begins with a number of zero bits.  The average work required is exponential in the number of zero bits required and can be verified by executing a single hash.For our timestamp network, we implement the proof-of-work by incrementing a nonce in the block until a value is found that gives the block's hash the required zero bits.  Once the CPU effort  has been expended to make it  satisfy the proof-of-work, the  block cannot  be  changed without redoing the work.  As later blocks are chained after it, the work to change the block would include redoing all the blocks after it.The proof-of-work also solves the problem of determining representation in majority decision making.  If the majority were based on one-IP-address-one-vote, it could be subverted by anyone able  to  allocate  many  IPs.   Proof-of-work  is  essentially  one-CPU-one-vote.   The  majority decision is represented by the longest chain, which has the greatest proof-of-work effort invested in it.  If a majority of CPU power is controlled by honest nodes, the honest chain will grow the fastest and outpace any competing chains.  To modify a past block, an attacker would have to redo the proof-of-work of the block and all blocks after it and then catch up with and surpass the work of the honest nodes.  We will show later that the probability of a slower attacker catching up diminishes exponentially as subsequent blocks are added.\", \"To compensate for increasing hardware speed and varying interest in running nodes over time, the proof-of-work difficulty is determined by a moving average targeting an average number of blocks per hour.  If they're generated too fast, the difficulty increases.5. NetworkThe steps to run the network are as follows:1) New transactions are broadcast to all nodes.2) Each node collects new transactions into a block.  3) Each node works on finding a difficult proof-of-work for its block.4) When a node finds a proof-of-work, it broadcasts the block to all nodes.5) Nodes accept the block only if all transactions in it are valid and not already spent.6) Nodes express their acceptance of the block by working on creating the next block in the chain, using the hash of the accepted block as the previous hash.Nodes always consider the longest chain to be the correct one and will keep working on extending it.  If two nodes broadcast different versions of the next block simultaneously, some nodes may receive one or the other first.  In that case, they work on the first one they received, but save the other branch in case it becomes longer.  The tie will be broken when the next proof-of-work is found and one branch becomes longer;  the nodes that were working on the other branch will then switch to the longer one.3BlockPrev Hash NonceTx Tx .BlockPrev Hash NonceTx Tx .New transaction broadcasts do not necessarily need to reach all nodes.  As long as they reach many nodes, they will get into a block before long.  Block broadcasts are also tolerant of dropped messages.  If a node does not receive a block, it will request it when it receives the next block and realizes it missed one.6. IncentiveBy convention, the first transaction in a block is a special transaction that starts a new coin owned by the creator of the block.  This adds an incentive for nodes to support the network, and provides a way to initially distribute coins into circulation, since there is no central authority to issue them. The steady addition of a constant of amount of new coins is analogous to gold miners expending resources to add gold to circulation.  In our case, it is CPU time and electricity that is expended.The incentive can also be funded with transaction fees.  If the output value of a transaction is less than its input value, the difference is a transaction fee that is added to the incentive value of the  block  containing  the  transaction.   Once  a  predetermined  number  of  coins  have  entered circulation, the incentive can transition entirely to transaction fees and be completely inflation free.The incentive  may help  encourage nodes to  stay  honest.   If  a  greedy attacker  is  able  to assemble more CPU power than all the honest nodes, he would have to choose between using it to defraud people by stealing back his payments, or using it to generate new coins.  He ought to find it more profitable to play by the rules, such rules that favour him with more new coins than everyone else combined, than to undermine the system and the validity of his own wealth.7. Reclaiming Disk SpaceOnce the latest transaction in a coin is buried under enough blocks, the spent transactions before it  can be discarded to  save disk  space.   To facilitate  this  without  breaking the  block's  hash, transactions are hashed in a Merkle Tree [7][2][5], with only the root included in the block's hash. Old blocks can then be compacted by stubbing off branches of the tree.  The interior hashes do not need to be stored.A block header with no transactions would be about 80 bytes.   If we suppose blocks are generated every 10 minutes, 80 bytes * 6 * 24 * 365 = 4.2MB per year.  With computer systems typically selling with 2GB of RAM as of 2008, and Moore's Law predicting current growth of 1.2GB per year,  storage should not be a problem even if  the block headers must  be kept in memory.4\", '4BlockBlockBlock Header (Block Hash)Prev Hash NonceHash01Hash0 Hash1 Hash2 Hash3Hash23Root HashHash01Hash2Tx3Hash23Block Header (Block Hash)Root HashTransactions Hashed in a Merkle Tree After Pruning Tx0-2 from the BlockPrev Hash NonceHash3Tx0 Tx1 Tx2 Tx38. Simplified Payment VerificationIt is possible to verify payments without running a full network node.  A user only needs to keep a copy of the block headers of the longest proof-of-work chain, which he can get by querying network  nodes  until  he\\'s  convinced  he  has  the  longest  chain,  and  obtain  the  Merkle  branch linking  the  transaction  to  the  block  it\\'s  timestamped  in.   He  can\\'t  check  the  transaction  for himself, but by linking it to a place in the chain, he can see that a network node has accepted it, and blocks added after it further confirm the network has accepted it.As such, the verification is reliable as long as honest nodes control the network, but is more vulnerable  if  the  network  is  overpowered  by  an  attacker.   While  network  nodes  can  verify transactions  for  themselves,  the  simplified  method  can  be  fooled  by an  attacker\\'s  fabricated transactions for as long as the attacker can continue to overpower the network.  One strategy to protect against this would be to accept alerts from network nodes when they detect an invalid block,  prompting  the  user\\'s  software  to  download  the  full  block  and  alerted  transactions  to confirm the inconsistency.  Businesses that receive frequent payments will probably still want to run their own nodes for more independent security and quicker verification.9. Combining and Splitting ValueAlthough it  would be possible to handle coins individually, it  would be unwieldy to make a separate  transaction  for  every cent  in  a  transfer.   To  allow value  to  be  split  and  combined, transactions contain multiple inputs and outputs.  Normally there will be either a single input from a larger previous transaction or multiple inputs combining smaller amounts, and at most two outputs: one for the payment, and one returning the change, if any, back to the sender.  It should be noted that fan-out, where a transaction depends on several transactions, and those transactions depend on many more, is not a problem here.  There is never the need to extract a complete standalone copy of a transaction\\'s history.5TransactionIn.In Out.Hash01Hash2 Hash3Hash23Block HeaderMerkle RootPrev Hash NonceBlock HeaderMerkle RootPrev Hash NonceBlock HeaderMerkle RootPrev Hash NonceMerkle Branch for Tx3Longest Proof-of-Work ChainTx310. PrivacyThe traditional banking model achieves a level of privacy by limiting access to information to the parties involved and the trusted third party.  The necessity to announce all transactions publicly precludes this method, but privacy can still be maintained by breaking the flow of information in another place: by keeping public keys anonymous.  The public can see that someone is sending an amount to someone else, but without information linking the transaction to anyone.  This is similar  to  the  level  of  information released by stock exchanges,  where  the  time and size  of individual trades, the \"tape\", is made public, but without telling who the parties were.As an additional firewall, a new key pair should be used for each transaction to keep them from being  linked  to  a  common owner.   Some  linking  is  still  unavoidable  with  multi-input transactions, which necessarily reveal that their inputs were owned by the same owner.  The risk is that if the owner of a key is revealed, linking could reveal other transactions that belonged to the same owner.', \"11. CalculationsWe consider the scenario of an attacker trying to generate an alternate chain faster than the honest chain.  Even if this is accomplished, it does not throw the system open to arbitrary changes, such as creating value out of thin air or taking money that never belonged to the attacker.  Nodes are not going to accept an invalid transaction as payment, and honest nodes will never accept a block containing them.  An attacker can only try to change one of his own transactions to take back money he recently spent.The race between the honest chain and an attacker chain can be characterized as a Binomial Random Walk.  The success event is the honest chain being extended by one block, increasing its lead by +1, and the failure event is the attacker's chain being extended by one block, reducing the gap by -1.The probability of an attacker catching up from a given deficit is analogous to a Gambler's Ruin problem.  Suppose a gambler with unlimited credit starts at a deficit and plays potentially an infinite number of trials to try to reach breakeven.  We can calculate the probability he ever reaches breakeven, or that an attacker ever catches up with the honest chain, as follows [8]:p = probability an honest node finds the next blockq = probability the attacker finds the next blockqz = probability the attacker will ever catch up from z blocks behindq z={ 1 if p≤q\\ue09eq / p\\ue09fz if p\\ue085q}6Identities Transactions TrustedThird Party Counterparty PublicIdentities Transactions PublicNew Privacy ModelTraditional Privacy ModelGiven our assumption that p > q, the probability drops exponentially as the number of blocks the attacker has to catch up with increases.  With the odds against him, if he doesn't make a lucky lunge forward early on, his chances become vanishingly small as he falls further behind.We now consider how long the recipient of a new transaction needs to wait  before being sufficiently certain the sender can't change the transaction.  We assume the sender is an attacker who wants to make the recipient believe he paid him for a while, then switch it to pay back to himself after some time has passed.  The receiver will be alerted when that happens, but the sender hopes it will be too late.The receiver generates a new key pair and gives the public key to the sender shortly before signing.  This prevents the sender from preparing a chain of blocks ahead of time by working on it continuously until he is lucky enough to get far enough ahead, then executing the transaction at that moment.  Once the transaction is sent, the dishonest sender starts working in secret on a parallel chain containing an alternate version of his transaction.The recipient waits until the transaction has been added to a block and  z blocks have been linked  after  it.   He  doesn't  know the  exact  amount  of  progress  the  attacker  has  made,  but assuming the honest blocks took the average expected time per block, the attacker's potential progress will be a Poisson distribution with expected value:\\ue0c1=z qpTo get the probability the attacker could still catch up now, we multiply the Poisson density for each amount of progress he could have made by the probability he could catch up from that point:∑k=0∞ \\ue0c1k e−\\ue0c1k !⋅{\\ue09eq / p\\ue09f\\ue09e z−k \\ue09f if k≤ z1 if k\\ue085 z}Rearranging to avoid summing the infinite tail of the distribution.1−∑k=0z \\ue0c1k e−\\ue0c1k !\\ue09e1−\\ue09eq / p\\ue09f\\ue09e z−k \\ue09f\\ue09fConverting to C code.#include <math.h>double AttackerSuccessProbability(double q, int z){    double p = 1.0 - q;    double lambda = z * (q / p);    double sum = 1.0;    int i, k;    for (k = 0; k <= z; k++)    {        double poisson = exp(-lambda);        for (i = 1; i <= k; i++)            poisson *= lambda / i;        sum -= poisson * (1 - pow(q / p, z - k));    }    return sum;}7Running some results, we can see the probability drop off exponentially with z.\", '7Running some results, we can see the probability drop off exponentially with z.q=0.1z=0    P=1.0000000z=1    P=0.2045873z=2    P=0.0509779z=3    P=0.0131722z=4    P=0.0034552z=5    P=0.0009137z=6    P=0.0002428z=7    P=0.0000647z=8    P=0.0000173z=9    P=0.0000046z=10   P=0.0000012q=0.3z=0    P=1.0000000z=5    P=0.1773523z=10   P=0.0416605z=15   P=0.0101008z=20   P=0.0024804z=25   P=0.0006132z=30   P=0.0001522z=35   P=0.0000379z=40   P=0.0000095z=45   P=0.0000024z=50   P=0.0000006Solving for P less than 0.1%.P < 0.001q=0.10   z=5q=0.15   z=8q=0.20   z=11q=0.25   z=15q=0.30   z=24q=0.35   z=41q=0.40   z=89q=0.45   z=34012. ConclusionWe have proposed a system for electronic transactions without relying on trust.  We started with the usual framework of coins made from digital  signatures,  which provides strong control of ownership,  but  is  incomplete  without  a  way  to  prevent  double-spending.   To  solve  this,  we proposed a peer-to-peer network using proof-of-work to record a public history of transactions that  quickly  becomes  computationally  impractical  for  an  attacker  to  change  if  honest  nodes control a majority of CPU power.  The network is robust in its unstructured simplicity.  Nodes work all at once with little coordination.  They do not need to be identified, since messages are not routed to any particular place and only need to be delivered on a best effort basis.  Nodes can leave  and  rejoin  the  network  at  will,  accepting  the  proof-of-work  chain  as  proof  of  what happened while they were gone.  They vote with their CPU power, expressing their acceptance of valid blocks by working on extending them and rejecting invalid blocks by refusing to work on them.  Any needed rules and incentives can be enforced with this consensus mechanism.8References[1] W. Dai, \"b-money,\" http://www.weidai.com/bmoney.txt, 1998.[2] H. Massias, X.S. Avila, and J.-J. Quisquater, \"Design of a secure timestamping service with minimal trust requirements,\" In 20th Symposium on Information Theory in the Benelux, May 1999.[3] S. Haber, W.S. Stornetta, \"How to time-stamp a digital document,\" In Journal of Cryptology, vol 3, no 2, pages 99-111, 1991.[4] D. Bayer, S. Haber, W.S. Stornetta, \"Improving the efficiency and reliability of digital time-stamping,\" In Sequences II: Methods in Communication, Security and Computer Science, pages 329-334, 1993.[5] S. Haber, W.S. Stornetta, \"Secure names for bit-strings,\" In Proceedings of the 4th ACM Conference on Computer and Communications Security, pages 28-35, April 1997.[6] A. Back, \"Hashcash - a denial of service counter-measure,\" http://www.hashcash.org/papers/hashcash.pdf, 2002.[7] R.C. Merkle, \"Protocols for public key cryptosystems,\" In Proc. 1980 Symposium on Security and Privacy, IEEE Computer Society, pages 122-133, April 1980.[8] W. Feller, \"An introduction to probability theory and its applications,\" 1957.9']\n"
     ]
    }
   ],
   "source": [
    "from tika import parser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "try:\n",
    "    document = parser.from_file('Test_document_usecase-1.pdf')\n",
    "    data = document['content']\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter()\n",
    "paragraphs = splitter.split_text(text=data)\n",
    "\n",
    "def clean_text(text):\n",
    "    cleaned_string = text.replace(\"\\n\",\"\").replace('..',\"\")\n",
    "    return cleaned_string\n",
    "\n",
    "cleaned_paragraph = [clean_text(para) for para in paragraphs]\n",
    "print(cleaned_paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "711c5f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in /Users/dsubramanian/opt/anaconda3/lib/python3.9/site-packages (1.7.4)\n",
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9978bfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /Users/dsubramanian/.cache/torch/sentence_transformers/cross-encoder_stsb-roberta-large. Creating a new one with MEAN pooling.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at /Users/dsubramanian/.cache/torch/sentence_transformers/cross-encoder_stsb-roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "# Creating the Cross Encoder\n",
    "model_encoder = SentenceTransformer('cross-encoder/stsb-roberta-large')\n",
    "\n",
    "# Creating the Vector Encoder\n",
    "model_vector = SentenceTransformer('msmarco-distilbert-base-v4')\n",
    "\n",
    "# Encoding sentences\n",
    "sentences = model_vector.encode(cleaned_paragraph)\n",
    "\n",
    "# Defining the dimension for the Faiss index\n",
    "dimension = 768  # Adjust the dimension based on your sentence embeddings\n",
    "\n",
    "# Number of neighbors to search for\n",
    "neighbour = 10\n",
    "\n",
    "# Initializing the Faiss index\n",
    "index = faiss.IndexFlatIP(dimension)\n",
    "\n",
    "# Adding sentences to the index\n",
    "index.add(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "990a062f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I help you:Protocols for public key cryptosystems\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4m/86yjzx61095f32qjrs3nfd040000gp/T/ipykernel_16872/2080569605.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Creating query vectors and fetching relevant indexes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mquery_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbour\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mrelevant_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Index' is not defined"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import numpy as np\n",
    "\n",
    "# defining OpenAI API key\n",
    "api_key = \"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\"\n",
    "openai.api_key = api_key\n",
    "\n",
    "#creating query vectors and fetching relevant indexes \n",
    "\n",
    "while True:\n",
    "    query = input(\"How can I help you:\")\n",
    "\n",
    "    if not query:\n",
    "        break\n",
    "\n",
    "    # Creating query vectors and fetching relevant indexes\n",
    "    query_vector = model_vector.encode([query])\n",
    "    D, I = Index.search(query_vector, neighbour)\n",
    "    relevant_indexes = I.tolist()[0]\n",
    "\n",
    "    # Using indexes to get relevant paragraphs\n",
    "    relevant_paras = [cleaned_paragraph[i] for i in relevant_indexes]\n",
    "\n",
    "    # Creating query-paragraph pairs and calculate similarity scores to rank paragraphs\n",
    "    query_paras_combined = [[query, para] for para in relevant_paras]\n",
    "    similarity_scores = model_encoder.predict(query_paras_combined)\n",
    "    sim_scores_argsort = list(reversed(np.argsort(similarity_scores)))\n",
    "\n",
    "    print(\"Similarity Scores:\")\n",
    "    for idx in sim_scores_argsort:\n",
    "        print(f\"{similarity_scores[idx]:.2f}\\t{relevant_paras[idx]}\")\n",
    "        print(f\"Paragraph Index: {relevant_indexes[idx]}\")\n",
    "\n",
    "    # Generating an input prompt\n",
    "    relevant_context = \"\\n\".join(relevant_paras)\n",
    "    refined_prompt = f\"\"\"Answer the question based on the contexts below.\n",
    "If the question cannot be answered using the information, provide the answer as \"I don't know.\"\n",
    "\n",
    "### Contexts:\n",
    "{relevant_context}\n",
    "\n",
    "### Question: {query}\n",
    "Answer: \"\"\"\n",
    "\n",
    "    print(\"Refined Prompt:\")\n",
    "    print(redefined_prompt)\n",
    "\n",
    "    # Feed input to the OpenAI model\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=refined_prompt,\n",
    "        temperature=0.0,\n",
    "        max_tokens=1024,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "\n",
    "    print(\"Answer from the model:\")\n",
    "    print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe48cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
